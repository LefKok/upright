#summary How to configure and run HDFS-UpRight

= Download =
  You need to donwload both the UpRight library and HDFS-UpRight.

= Configuration =

  # UpRight must be configured properly. See [UpRightConfigurationExecution UpRight Configuration]. Notice that only namenode is replicated by UpRight, so namenodes are "UpRight servers" and datanodes are "UpRight clients". Therefore, when configuring UpRight, you should list all datanodes as clients.
  # HDFS also needs to be configured properly. See [http://hadoop.apache.org/core/docs/current/cluster_setup.html#Configuration Hadoop Configuration].
  # Incorporate HDFS with UpRight: modify hdfs-site.xml, add the following four options.
    # dfs.bft is a boolean value about whether to use bft namenode.
    # dfs.bft.datanode is a boolean value about whether to use bft datanode.
    # bft.configurationFile is the name of the UpRight configuration file generated in the first step.
    # bft.shimId is the id of the corresponding node defined in the UpRight configuration file.
  Typically, dfs.bft and dfs.bft.datanode should be "true" and bft.configurationFile should point to the same file on all the nodes, but bft.shimId should be different on different machines.

{{{
  <property>
    <name>dfs.bft</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.bft.datanode</name>
    <value>false</value>
  </property>

  <property>
    <name>bft.configurationFile</name>
    <value>/users/sangmin/bft-hdfs-demo/config.properties</value>
  </property>


  <property>
    <name>bft.shimId</name>
    <value>0</value>
  </property>
}}}

= Run HDFS-UpRight =
* Start UpRight Core as described in [UpRightConfigurationExecution UpRight Configuration].
* Start namenode: on each namenode machine, run "bin/hadoop namenode --config configDir"
* Start datanode: on each datanode machine, run "bin/hadoop datanode --config configDir"
* Start clients: this depends on your application.