#summary How to configure and run HDFS-UpRight

= Download =
You need to donwload both the [http://upright.googlecode.com/files/upright.tar.gz UpRight] library and the [http://upright.googlecode.com/files/hdfs-upright-0.1.tar.gz HDFS-UpRight].

= Configuration =

 # UpRight must be configured properly. See [UpRightConfigurationExecution UpRight Configuration]. Notice that only namenode is replicated by UpRight, so namenodes are "UpRight servers" and datanodes are "UpRight clients". Therefore, when configuring UpRight, you should list all datanodes as clients.
 # HDFS also needs to be configured properly. See [http://hadoop.apache.org/core/docs/current/cluster_setup.html#Configuration Hadoop Configuration].
 # Modify hadoop-site.xml to add the following two properties.
    * _dfs.bft_ : whether to use UpRight replication for namenode or not.
    * _dfs.bft.datanode_ : whether to use UpRight datanode or not.

{{{
  <property>
    <name>dfs.bft</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.bft.datanode</name>
    <value>false</value>
  </property>

}}}

= Run HDFS-UpRight =
Do not use `start-all.sh`, `stop-all.sh`, `start-dfs.sh` and `stop-dfs.sh` to start/stop HDFS-UpRight. Instead, please follow the instructions below.
== Start UpRight Core ==
First, start UpRight Core as described in [UpRightConfigurationExecution UpRight Configuration]. 
== Start namenodes ==
On each namenode machine, we need to run a primary namenode and a helper namenode. Before executing them, we need to format HDFS:
   `bin/hadoop [--config <PathToHDFSConfigDir>] namenode -format`
Also format HDFS for the helper:
   `bin/hadoop [--config <PathToHDFSConfigDir>] namenode -helper -format`
Then start a helper namenode first:
   `bin/hadoop [--config <PathToHDFSConfigDir>] namenode -helper &`
And finally start a primary namenode:
   `bin/hadoop [--config <PathToHDFSConfigDir>] namenode -shimid <UpRightServerID> -uprightconfig <PathToUpRightConfigFile>`

Typically you will also want to redirect stdout and stderr of primary/helper namenode to some log files. The following is an example of sequence of commands to run the first namenode replica:
{{{
 Formatting HDFS
 $ bin/hadoop namenode -format
 $ bin/hadoop namenode -helper -format

 Starting a helper namenode
 $ bin/hadoop namenode -helper 2>&1 logs/helper.log &

 Starting a primary namenode
 $ bin/hadoop namenode -shimid 0 -uprightconfig ./uprightConfig 2>&1 logs/primary_0.log  &
}}}
 
== Start UpRight client proxies ==
On each machine on which a HDFS datanode or HDFS clients run, 
  `bin/hadoop [--config <PathToHDFSConfigDir>] uprightclientproxy <UpRightClientID> <PathToUpRightConfigFile>`
Following is an example to run an UpRight client proxy:
{{{
$ bin/hadoop uprightclientproxy 0 ./uprightConfig 2>&1 logs/clientproxy_0.log  &
}}}

== Start datanodes and clients ==
At this point, you can run datanodes and any applications that run on HDFS in the same way as original HDFS.