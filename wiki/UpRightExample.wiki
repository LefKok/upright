#summary A simple example of how to implement the upright interfaces.

The source code of this example can be found in Applications/hashtable. This example application provides the functions of a remote hashtable, in which the client can read or write a key-value pair on the server. To illustrate how to handle nondeterminism in server replicas, we extended the functions of the hashtable a bit: when the server receives a write request, it also records the modification time in the hashtable. Furthermore, it also generates a random number for this key/value pair. The client can read the random number and timestamp through the read request.

=Define Requests and Replies=
First, the programmer must define the request and reply between client and server. In this example, they are defined in HTRequest.java and HTReply.java. These two files are simple and this step is of no difference to other distributed systems, so we do not describe it in detail. UpRight library considers all requests and replies as byte arrays, so we also provided Convert.java to convert objects to and from byte arrays.

=Implement the Server=
The server implementation is mainly in HTServer.java. The server class must implement the two server interfaces:
{{{
public class HTServer implements MainAppCPInterface, BackupAppCPInterface
}}}

===Data Structures===
The key data structure is a hashtable: (DataUnit is a triple of value, random number and timestamp):
{{{
LinkedHashMap<String, DataUnit> ht;
}}}
To demonstrate how to keep states, we also add an extra variable, which is added by one for each write operation.
{{{
int writeCount=0;
}}}
The CPAppInterface provides the callback for each function. We will show how to instantiate it later.
{{{
CPAppInterface generalCP=null;
}}}
We use an ArrayList to cache requests. This ArrayList serves as an in memory log and when the server library asks to write log to disk, we write this whole ArrayList to a file and then clear the ArrayList.
{{{
ArrayList<LogEntry> logs=new ArrayList<LogEntry>();
}}}
And two strings are used store the directory to write log and checkpoint file. We can see later these two are used when instantiating the CPAppInterface object.
{{{
private String logDir=null;
private String syncDir=null;
}}}
===Constructor===
Initialize everything:
{{{
        public HTServer(String logDir, String syncDir) throws IOException {
               this.logDir=logDir+File.separator;
                this.syncDir=syncDir+File.separator;
                ht = new LinkedHashMap<String, DataUnit>();
                File logDir2 = new File(this.logDir);
                logDir2.mkdirs();
                File syncDir2 = new File(this.syncDir);
                syncDir2.mkdirs();
        }
}}}

===Execute a request===
If it is read request, then get the data from the hashtable. If it is a write request, then write to hashtable and increase writeCount. Call execDone finally. Several notices here:
  # This function shows how to use random number and time deterministically: use RequestInfo.getRandom() and RequestInfo.getTime() instead of using java library functions.
  # Write request is logged in this function. Most storage system requires logs to be written to disk before replying to the client. However, UpRight does not have this restriction. We can see here the server just logs the request in memory and then replies. The reason is that UpRight Core writes each request to disk and if the server crashes, the UpRight Core resends these requests to the server, so there will be no data lost.


{{{
        @Override
        public synchronized void execAsync(byte[] request, RequestInfo info) {
                HTRequest req = (HTRequest)(Convert.bytesToObject(request));
                HTReply rep = null;
                String key = req.getKey();
                if(req.getType() == HTRequest.READ){
                        if(ht.containsKey(key)){
                                rep = new HTReply(false, ht.get(key));
                        }else{
                                rep = new HTReply(true, null);
                        }
                } else {        // WRITE operation
                        //Write requests must be logged. 
                        DataUnit data=new DataUnit(req.getValue(), info.getRandom(), info.getTime());
                        logs.add(new LogEntry(key,data));
                        ht.put(key, data);
                        writeCount++;
                        rep = new HTReply(false, null);
                }
                generalCP.execDone(Convert.objectToBytes(rep), info);

        }
}}}

=== Write Log to Disk ===
This function writes all in memory logs to disk. It calls flushDone finally. Notice that the content and the name of the log file must be deterministic. The application should not modify the log file after calling flushDone.
{{{
        @Override
        public synchronized void flushAndStartNewLog(long seqNo) {
                File logFile=new File(this.logDir+"ht_log_"+seqNo);
                try {
                        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(logFile));
                        oos.writeObject(logs);
                        oos.close();
                        logs.clear();
                        generalCP.flushDone(seqNo, logFile.getAbsolutePath());
                } catch (IOException e) {
                        e.printStackTrace();
                }
        }
}}}

=== Replay the Log ===
Replay log is performed when 1) the _Main_ server instance passes the information to the _Backup_ server instance and 2) when both servers need recovery. This function reads information from the log file and update the in-memory data structures. Notice that writeCount is also updated here, even if it is not recorded in the log file.
{{{
        @Override
        public void consumeLog(String fileName) {
                ObjectInputStream is = null;
                try {
                        is = new ObjectInputStream(new FileInputStream(fileName));
                        ArrayList<LogEntry> tmp=(ArrayList<LogEntry>)is.readObject();
                        is.close();
                        for(LogEntry e:tmp){
                                ht.put(e.getKey(), e.getData());
                                writeCount++;
                        }
                } catch (Exception e) {
                        e.printStackTrace();
                }

                generalCP.consumeLogDone(fileName);
        }
}}}

=== Write Checkpoint to Disk ===
This function writes the whole application states to the disk. The application should be able to fully recover from this checkpoint without previous logs. Previous log will be discarded to save disk space. However, do not delete log files in your application. The UpRight server library will perform this task. In this example, both the hashtable and the writeCount are written to disk. It calls syncDone finally.
{{{
        @Override
        public void sync() {
                try {
                        File syncFile=new File(this.syncDir+"ht_sync_"+writeCount);
                        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(syncFile));
                        oos.writeObject(ht);
                        oos.writeInt(writeCount);
                        oos.close();
                }
                catch (Exception e) {
                        e.printStackTrace();
                }
                generalCP.syncDone(this.syncDir+"ht_sync_"+writeCount);
        }
}}}


=== Load the Checkpoint ===
This function is performed during recovery. In this example, the application reads the hashtable and the writeCount from the checkpoint file. It calls loadSnapshotDone finally.
{{{
        @Override
        public synchronized void loadSnapshot(String fileName) {
                try {
                        ObjectInputStream ois = new ObjectInputStream(new FileInputStream(fileName));
                        ht = (LinkedHashMap<String, DataUnit>) ois.readObject();
                        writeCount = ois.readInt();
                        generalCP.loadSnapshotDone();
                } catch (Exception e) {
                        e.printStackTrace();
                }

        }
}}}

=== Connect Application server to UpRight ===
The main function shows how to connect application server to UpRight. First, it creates the GeneralCP class object, which implements CPAppInterface. Then it creates the two server instances and finally calls setupApplication to register them to UpRight. This will startup the UpRight state machine.
{{{
        public static void main(String args[]) throws Exception{
                if(args.length!=4){
                        System.out.println("Usage: java Applications.hashtable <id> <config_file> <log_path> <snapshot_path>");
                }
                GeneralCP generalCP = new GeneralCP(Integer.parseInt(args[0]), args[1], args[2], args[3]);
                HTServer main = new HTServer(args[2],args[3]);
                HTServer helper = new HTServer(args[2], args[3]);
                main.setGenCP(generalCP);
                helper.setGenCP(generalCP);
                generalCP.setupApplication(main, helper);
        }
}}}

= Implement the Client=
The client code HTClient.java is simple. It uses ClientShimBaseNode.execute to send requests and then handle the reply.
{{{
package Applications.hashtable;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.StringTokenizer;

import BFT.clientShim.ClientShimBaseNode;
import BFT.network.TCPNetwork;



public class HTClient{
        ClientShimBaseNode clientShim;
        public HTClient(String membership, int id){
                clientShim = new ClientShimBaseNode(membership, id);
                clientShim.setNetwork(new TCPNetwork(clientShim));
                clientShim.start();
        }

        public void write(String key, int value)
        {
                HTRequest req = new HTRequest(HTRequest.WRITE, key, value);
                byte[] replyBytes = clientShim.execute(Convert.objectToBytes(req));
                HTReply rep=(HTReply)(Convert.bytesToObject(replyBytes));
                if(rep.isError()){
                        throw new RuntimeException("Write failed");
                }
        }

        public DataUnit read(String key){
                HTRequest req = new HTRequest(HTRequest.READ, key, 0);
                byte [] replyBytes = clientShim.execute(Convert.objectToBytes(req));
                HTReply rep = (HTReply)(Convert.bytesToObject(replyBytes));
                if(rep.isError()){
                      throw new RuntimeException("Read failed");
                }
                return rep.getData();
        }

        public static void main(String[] args){
                String membership=args[0];
                int id=Integer.parseInt(args[1]);
                HTClient client=new HTClient(membership, id);
                client.write("1",1);
                DataUnit data=client.read("1");
                System.out.println("value="+data.getValue());
                System.out.println("random="+data.getRandom());
                System.out.println("timestamp="+data.getTimestamp());
                System.exit(0);
        }
}
}}}

=Compile and Run the example=
  * [UpRightInstall Compile your code with UpRight].
  * [UpRightConfigurationExecution Generate your configuration]. In the following steps, we assume you use the (1 order, 1 server, 1 client) configuration on localhost.
  * Start the UpRight Core Order nodes: 
    {{{
    java -cp conf:upright.jar:FlexiCoreProvider-1.6p3.signed.jar:CoDec-build17-jdk13.jar BFT.order.OrderBaseNode 0 test.properties
    }}}
  * Start the server:
    {{{
    java -cp conf:upright.jar:FlexiCoreProvider-1.6p3.signed.jar:CoDec-build17-jdk13.jar  Applications.hashtable.HTServer 0 test.properties /tmp/httest/0/log /tmp/httest/0/ss
    }}}

  * Start the client:
    {{{
    java -cp conf:upright.jar:FlexiCoreProvider-1.6p3.signed.jar:CoDec-build17-jdk13.jar Applications.hashtable.HTClient test.properties 0
    }}}
    You should be able to see it outputs a value 1, a random number and a timestamp.

    In the unreplicated configuration, all nodes have index 0. To run a replicated version, you just need to start all nodes on every machine, with the correct index number. 